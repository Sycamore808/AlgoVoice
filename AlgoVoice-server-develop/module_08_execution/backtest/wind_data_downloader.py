#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Windæ•°æ®ä¸‹è½½å™¨ - ä¸‹è½½å¹¶æœ¬åœ°å­˜å‚¨å†å²æ•°æ®
"""
import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import pickle
import logging
from typing import Optional, List, Dict
import time

# è®¾ç½®UTF-8ç¼–ç è¾“å‡º
if sys.platform == 'win32':
    import codecs
    if sys.stdout.encoding != 'utf-8':
        sys.stdout.reconfigure(encoding='utf-8')
    if sys.stderr.encoding != 'utf-8':
        sys.stderr.reconfigure(encoding='utf-8')

logger = logging.getLogger(__name__)

class WindDataDownloader:
    """Windæ•°æ®ä¸‹è½½å™¨ï¼Œè´Ÿè´£ä¸‹è½½å’Œæœ¬åœ°å­˜å‚¨"""
    
    def __init__(self, data_dir: str = "data/backtest_data"):
        """
        åˆå§‹åŒ–æ•°æ®ä¸‹è½½å™¨
        
        Args:
            data_dir: æ•°æ®å­˜å‚¨ç›®å½•
        """
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®å­ç›®å½•
        self.daily_dir = self.data_dir / "daily"
        self.index_dir = self.data_dir / "index"
        self.industry_dir = self.data_dir / "industry"
        self.metadata_dir = self.data_dir / "metadata"
        
        for dir_path in [self.daily_dir, self.index_dir, self.industry_dir, self.metadata_dir]:
            dir_path.mkdir(exist_ok=True)
        
        self.w = None
        self._wind_connected = False
        
    def connect_wind(self) -> bool:
        """è¿æ¥Windç»ˆç«¯"""
        try:
            from WindPy import w
            self.w = w
            
            # å¯åŠ¨Wind
            result = self.w.start()
            if result.ErrorCode != 0:
                logger.error(f"Windå¯åŠ¨å¤±è´¥: {result.Data}")
                return False
            
            self._wind_connected = True
            logger.info("âœ… Windç»ˆç«¯è¿æ¥æˆåŠŸ")
            return True
            
        except ImportError:
            logger.error("âŒ WindPyæœªå®‰è£…")
            return False
        except Exception as e:
            logger.error(f"âŒ Windè¿æ¥å¤±è´¥: {e}")
            return False
    
    def download_stock_list(self, trade_date: str = None) -> pd.DataFrame:
        """
        ä¸‹è½½è‚¡ç¥¨åˆ—è¡¨
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸ YYYYMMDDï¼Œé»˜è®¤ä¸ºæœ€æ–°äº¤æ˜“æ—¥
            
        Returns:
            è‚¡ç¥¨åˆ—è¡¨DataFrame
        """
        if not self._wind_connected:
            if not self.connect_wind():
                return pd.DataFrame()
        
        try:
            # è·å–Aè‚¡åˆ—è¡¨
            logger.info("ğŸ“¥ ä¸‹è½½Aè‚¡åˆ—è¡¨...")
            result = self.w.wset(
                "sectorconstituent",
                f"date={trade_date or datetime.now().strftime('%Y%m%d')};sectorid=a001010100000000"
            )
            
            if result.ErrorCode != 0:
                logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {result.Data}")
                return pd.DataFrame()
            
            df = pd.DataFrame(result.Data, index=result.Fields).T
            logger.info(f"âœ… è·å–åˆ° {len(df)} åªè‚¡ç¥¨")
            
            # ä¿å­˜
            save_path = self.metadata_dir / "stock_list.pkl"
            df.to_pickle(save_path)
            
            return df
            
        except Exception as e:
            logger.error(f"ä¸‹è½½è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def download_daily_data(
        self, 
        stock_code: str, 
        start_date: str, 
        end_date: str
    ) -> Optional[pd.DataFrame]:
        """
        ä¸‹è½½å•åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ YYYY-MM-DD
            end_date: ç»“æŸæ—¥æœŸ YYYY-MM-DD
            
        Returns:
            æ—¥çº¿æ•°æ®DataFrame
        """
        if not self._wind_connected:
            if not self.connect_wind():
                return None
        
        try:
            # ä¸‹è½½è¡Œæƒ…æ•°æ®
            fields = "open,high,low,close,volume,amt,turn,free_turn,pct_chg,mkt_cap_ard"
            result = self.w.wsd(
                stock_code,
                fields,
                start_date,
                end_date,
                "Fill=Previous"
            )
            
            if result.ErrorCode != 0:
                logger.warning(f"è·å–{stock_code}æ•°æ®å¤±è´¥: {result.Data}")
                return None
            
            df = pd.DataFrame(result.Data, index=result.Fields, columns=result.Times).T
            df.index.name = 'date'
            df['code'] = stock_code
            
            return df
            
        except Exception as e:
            logger.error(f"ä¸‹è½½{stock_code}æ•°æ®å¤±è´¥: {e}")
            return None
    
    def download_all_stocks_data(
        self,
        start_date: str,
        end_date: str,
        chunk_size: int = 50,
        delay: float = 0.5
    ) -> bool:
        """
        æ‰¹é‡ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            chunk_size: æ¯æ‰¹ä¸‹è½½æ•°é‡
            delay: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = self.download_stock_list()
        if stock_list.empty:
            logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return False
        
        codes = stock_list['wind_code'].tolist() if 'wind_code' in stock_list.columns else []
        total = len(codes)
        
        logger.info(f"ğŸ“Š å¼€å§‹ä¸‹è½½ {total} åªè‚¡ç¥¨çš„æ•°æ®")
        logger.info(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
        
        success_count = 0
        failed_codes = []
        
        for i in range(0, total, chunk_size):
            chunk = codes[i:i+chunk_size]
            logger.info(f"â³ è¿›åº¦: {i+1}/{total} - {i+len(chunk)}/{total}")
            
            for code in chunk:
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    file_path = self.daily_dir / f"{code.replace('.', '_')}.pkl"
                    if file_path.exists():
                        logger.info(f"â­ï¸  {code} æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡")
                        success_count += 1
                        continue
                    
                    # ä¸‹è½½æ•°æ®
                    df = self.download_daily_data(code, start_date, end_date)
                    if df is not None and not df.empty:
                        # ä¿å­˜
                        df.to_pickle(file_path)
                        success_count += 1
                        logger.info(f"âœ… {code} ä¸‹è½½æˆåŠŸ ({len(df)} æ¡)")
                    else:
                        failed_codes.append(code)
                        logger.warning(f"âš ï¸  {code} ä¸‹è½½å¤±è´¥")
                    
                    # å»¶è¿Ÿé¿å…APIé™åˆ¶
                    time.sleep(delay)
                    
                except Exception as e:
                    failed_codes.append(code)
                    logger.error(f"âŒ {code} å¤„ç†å¤±è´¥: {e}")
        
        logger.info(f"\n{'='*60}")
        logger.info(f"âœ… ä¸‹è½½å®Œæˆ!")
        logger.info(f"ğŸ“Š æˆåŠŸ: {success_count}/{total}")
        logger.info(f"âŒ å¤±è´¥: {len(failed_codes)}/{total}")
        if failed_codes:
            logger.info(f"å¤±è´¥åˆ—è¡¨: {failed_codes[:10]}...")
        logger.info(f"{'='*60}\n")
        
        return len(failed_codes) == 0
    
    def download_index_data(
        self,
        index_code: str,
        start_date: str,
        end_date: str
    ) -> Optional[pd.DataFrame]:
        """
        ä¸‹è½½æŒ‡æ•°æ•°æ®
        
        Args:
            index_code: æŒ‡æ•°ä»£ç ï¼Œå¦‚ '000001.SH'ï¼ˆä¸Šè¯æŒ‡æ•°ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æŒ‡æ•°æ•°æ®DataFrame
        """
        if not self._wind_connected:
            if not self.connect_wind():
                return None
        
        try:
            logger.info(f"ğŸ“¥ ä¸‹è½½æŒ‡æ•° {index_code} æ•°æ®...")
            
            fields = "open,high,low,close,volume,amt,pct_chg"
            result = self.w.wsd(
                index_code,
                fields,
                start_date,
                end_date,
                ""
            )
            
            if result.ErrorCode != 0:
                logger.error(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {result.Data}")
                return None
            
            df = pd.DataFrame(result.Data, index=result.Fields, columns=result.Times).T
            df.index.name = 'date'
            df['code'] = index_code
            
            # ä¿å­˜
            save_path = self.index_dir / f"{index_code.replace('.', '_')}.pkl"
            df.to_pickle(save_path)
            
            logger.info(f"âœ… æŒ‡æ•°æ•°æ®ä¸‹è½½æˆåŠŸ ({len(df)} æ¡)")
            return df
            
        except Exception as e:
            logger.error(f"ä¸‹è½½æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            return None
    
    def download_industry_classification(self) -> Optional[pd.DataFrame]:
        """
        ä¸‹è½½è¡Œä¸šåˆ†ç±»æ•°æ®ï¼ˆç”³ä¸‡ä¸€çº§ï¼‰
        
        Returns:
            è¡Œä¸šåˆ†ç±»DataFrame
        """
        if not self._wind_connected:
            if not self.connect_wind():
                return None
        
        try:
            logger.info("ğŸ“¥ ä¸‹è½½è¡Œä¸šåˆ†ç±»æ•°æ®...")
            
            # è·å–æ‰€æœ‰è‚¡ç¥¨çš„ç”³ä¸‡ä¸€çº§è¡Œä¸š
            stock_list = self.download_stock_list()
            if stock_list.empty:
                return None
            
            codes = stock_list['wind_code'].tolist() if 'wind_code' in stock_list.columns else []
            
            # æ‰¹é‡è·å–è¡Œä¸š
            result = self.w.wss(
                codes,
                "industry_sw",
                f"tradeDate={datetime.now().strftime('%Y%m%d')};industryType=1"
            )
            
            if result.ErrorCode != 0:
                logger.error(f"è·å–è¡Œä¸šåˆ†ç±»å¤±è´¥: {result.Data}")
                return None
            
            df = pd.DataFrame({
                'code': result.Codes,
                'industry': result.Data[0] if result.Data else []
            })
            
            # ä¿å­˜
            save_path = self.industry_dir / "sw_industry_l1.pkl"
            df.to_pickle(save_path)
            
            logger.info(f"âœ… è¡Œä¸šåˆ†ç±»ä¸‹è½½æˆåŠŸ ({len(df)} åªè‚¡ç¥¨)")
            return df
            
        except Exception as e:
            logger.error(f"ä¸‹è½½è¡Œä¸šåˆ†ç±»å¤±è´¥: {e}")
            return None
    
    def download_all_required_data(
        self,
        start_date: str = "2000-01-01",
        end_date: str = "2025-12-10"
    ) -> bool:
        """
        ä¸‹è½½æ‰€æœ‰å¿…éœ€æ•°æ®ï¼ˆä¸€é”®ä¸‹è½½ï¼‰
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        """
        logger.info("\n" + "="*60)
        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½å›æµ‹æ‰€éœ€çš„æ‰€æœ‰æ•°æ®")
        logger.info("="*60 + "\n")
        
        success = True
        
        # 1. ä¸‹è½½è‚¡ç¥¨åˆ—è¡¨
        logger.info("\nã€1/4ã€‘ä¸‹è½½è‚¡ç¥¨åˆ—è¡¨")
        stock_list = self.download_stock_list()
        if stock_list.empty:
            logger.error("âŒ è‚¡ç¥¨åˆ—è¡¨ä¸‹è½½å¤±è´¥")
            success = False
        
        # 2. ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨æ—¥çº¿æ•°æ®
        logger.info("\nã€2/4ã€‘ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨æ—¥çº¿æ•°æ®")
        if not self.download_all_stocks_data(start_date, end_date):
            logger.warning("âš ï¸  éƒ¨åˆ†è‚¡ç¥¨æ•°æ®ä¸‹è½½å¤±è´¥")
            success = False
        
        # 3. ä¸‹è½½æŒ‡æ•°æ•°æ®
        logger.info("\nã€3/4ã€‘ä¸‹è½½æŒ‡æ•°æ•°æ®")
        indices = {
            '000001.SH': 'ä¸Šè¯æŒ‡æ•°',
            '000300.SH': 'æ²ªæ·±300',
            '000905.SH': 'ä¸­è¯500'
        }
        for code, name in indices.items():
            df = self.download_index_data(code, start_date, end_date)
            if df is None:
                logger.error(f"âŒ {name} æ•°æ®ä¸‹è½½å¤±è´¥")
                success = False
        
        # 4. ä¸‹è½½è¡Œä¸šåˆ†ç±»
        logger.info("\nã€4/4ã€‘ä¸‹è½½è¡Œä¸šåˆ†ç±»")
        industry_df = self.download_industry_classification()
        if industry_df is None:
            logger.error("âŒ è¡Œä¸šåˆ†ç±»ä¸‹è½½å¤±è´¥")
            success = False
        
        logger.info("\n" + "="*60)
        if success:
            logger.info("ğŸ‰ æ‰€æœ‰æ•°æ®ä¸‹è½½å®Œæˆï¼")
        else:
            logger.warning("âš ï¸  éƒ¨åˆ†æ•°æ®ä¸‹è½½å¤±è´¥ï¼Œä½†å¯ä»¥ç»§ç»­å›æµ‹")
        logger.info("="*60 + "\n")
        
        return success
    
    def get_data_summary(self) -> Dict:
        """è·å–å·²ä¸‹è½½æ•°æ®çš„æ‘˜è¦"""
        summary = {
            'daily_stocks': len(list(self.daily_dir.glob('*.pkl'))),
            'indices': len(list(self.index_dir.glob('*.pkl'))),
            'industry_files': len(list(self.industry_dir.glob('*.pkl'))),
            'metadata_files': len(list(self.metadata_dir.glob('*.pkl')))
        }
        
        # è®¡ç®—æ•°æ®å¤§å°
        total_size = sum(
            f.stat().st_size 
            for f in self.data_dir.rglob('*.pkl')
        ) / (1024 * 1024)  # MB
        
        summary['total_size_mb'] = round(total_size, 2)
        
        return summary


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    downloader = WindDataDownloader()
    
    # ä¸‹è½½æ‰€æœ‰æ•°æ®
    downloader.download_all_required_data(
        start_date="2000-01-01",
        end_date="2025-12-10"
    )
    
    # æ˜¾ç¤ºæ‘˜è¦
    summary = downloader.get_data_summary()
    print("\næ•°æ®ä¸‹è½½æ‘˜è¦:")
    print(f"  è‚¡ç¥¨æ•°æ®æ–‡ä»¶: {summary['daily_stocks']}")
    print(f"  æŒ‡æ•°æ•°æ®æ–‡ä»¶: {summary['indices']}")
    print(f"  è¡Œä¸šåˆ†ç±»æ–‡ä»¶: {summary['industry_files']}")
    print(f"  å…ƒæ•°æ®æ–‡ä»¶: {summary['metadata_files']}")
    print(f"  æ€»å¤§å°: {summary['total_size_mb']} MB")

